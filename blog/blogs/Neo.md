**An AI agent engineer**

*January 2025*

The possibility of creating production-grade AI agentic workflows increases with the release of each new reasoning model along with improvements in the models’ ability to call tools. Work traditionally performed by humans can now start to get offloaded to these AI agents. 

In this sense, the Software 2.0 era, where the computer effectively writes the code and executes the task is closing in. This also means that the Software as a Service era, where the software assisted the human agent, will slowly get augmented and replaced by the Service as Software era. In the Service as Software era, the AI agent(s), with access to tools, will try to achieve a high-level, abstract goal traditionally left to humans. This represents a major disruption in how humans have viewed their relationship with computers. AI agents with access to capital can allocate resources to hire human labor or to rent compute (e.g. GPUs) to execute tasks. 

Many roles traditionally held by humans in corporations will undergo disruption. Well-defined roles such as Sales Development Representative or Customer Support are already experiencing change. But in this write-up, I want to focus on the AI/ML engineer. What could be more disruptive than the AI agent acting as an AI/ML engineer, creating a virtuous feedback loop where the agent continuously improves its own capabilities? 

How can we build an AI/ML engineer? Let’s call him Neo. One method is to identify all the tasks that an AI engineer performs and try to build a system that can automate them. Another approach might be to take one specific task, typically performed by an AI engineer, automate it, and then gradually broaden Neo's capabilities. We will use the second approach as it provides a more constrained scope and allows an easier angle of attack. 

Let’s assume that Neo's initial competency is building a Retrieval Augmented Generation (RAG) system. What is the typical workflow used by engineers to build RAG systems? While creating a demo for RAG is straightforward—using a fixed large language model (LLM), embedding model, and other hyperparameters such as top-k, reranker, and chunk size—developing a production-grade RAG system involves a more intricate process. It requires searching through a wide range of hyperparameters (including parsers, LLMs, embedding models, etc.) and evaluating each combination to identify the optimal configuration.

Although searching for optimal hyperparameters is a compute-intensive task, it is a well-defined problem that Neo can systematically navigate. To achieve this, Neo needs to integrate an AutoML process that iterates through various options for retrieval and generation tools. Additionally, Neo requires an assistant LLM to evaluate and judge each configuration option.

Assuming that such an AutoML system is accessible as a tool, Neo must begin by collecting specific RAG requirements from the user. This can be performed via a chat interface where the user provides Neo information about their project scope and Neo asks clarifying questions to correctly interpret their needs of the user. In addition to getting access to the data, Neo always makes sure to request the user to share Golden Questions & Answers that Neo will use to evaluate and identify the optimal hyperparameters. 

Neo then has a formal handshake with the user on the requirements by delivering a requirements document that the user reviews and eventually agrees with. Based on the requirements document, Neo has to suggest an architecture for the RAG system and provide a project breakdown with milestones. The system design goes through another review cycle with the user. After formal approval of the system design, Neo can build the agreed-upon architecture and use the AutoML system to find the optimal RAG hyperparameters for the user. 

Neo can deploy the optimal configuration for the user, test it, and deliver the tested codebase along with documentation back to the user. Security and compliance checks also come in this phase. Finally, Neo enables system monitoring to ensure that the deployed system stays up. Neo also collects user feedback using thumbs up/thumbs down or by showing two responses and asking users to select the better one. Neo keeps a tab of the user interaction touch-points, to assess the maturity of the user he is dealing with to ensure that the documentation is readable and usable at their competence level.

Notice that Neo relied on AutoML capability to optimize the retriever and generation tool. To handle more use cases, Neo must identify each additional tool it requires and build mechanisms to optimize that tool. For instance, imagine a warehouse manager requests Neo to build a system that counts the number of humans in a video stream and send an email alert to the manager in case more than 10 humans are detected. Neo, in this case, would need to get requirements on how many video frames should be checked, the costs of the system, and then apply the most effective object detection model to identify the number of humans. 

*Take me [home](https://sameeurrehman.com/)* 
